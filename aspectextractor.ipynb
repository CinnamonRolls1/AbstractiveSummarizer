{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "import json\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Spacy\n"
     ]
    }
   ],
   "source": [
    "def init_spacy():\n",
    "    print(\"Loading Spacy\")\n",
    "    nlp=spacy.load(\"en_core_web_sm\")\n",
    "    return nlp\n",
    "nlp = init_spacy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    " def aspect_extractor(doc):\n",
    "    doc = nlp(doc)\n",
    "    prod_pronouns = ['it','this','they','these']\n",
    "    ## FIRST RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "    ## RULE = M is child of A with a relationship of amod\n",
    "    rule1_pairs = []\n",
    "    add_neg_pfx = False\n",
    "    for token in doc:\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        if token.dep_ == \"amod\" and not token.is_stop:\n",
    "            M = token.text\n",
    "            A = token.head.text\n",
    "\n",
    "            # add adverbial modifier of adjective (e.g. 'most comfortable headphones')\n",
    "            M_children = token.children\n",
    "            for child_m in M_children:\n",
    "                if(child_m.dep_ == \"advmod\"):\n",
    "                    M_hash = child_m.text\n",
    "                    M = M_hash + \" \" + M\n",
    "                    break\n",
    "\n",
    "            # negation in adjective, the \"no\" keyword is a 'det' of the noun (e.g. no interesting characters)\n",
    "            A_children = token.head.children\n",
    "            for child_a in A_children:\n",
    "                if(child_a.dep_ == \"det\" and child_a.text == 'no'):\n",
    "                    neg_prefix = 'not'\n",
    "                    M = neg_prefix + \" \" + M\n",
    "                    break\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            rule1_pairs.append((A, M,1))\n",
    "\n",
    "    ## SECOND RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "    #Direct Object - A is a child of something with relationship of nsubj, while\n",
    "    # M is a child of the same something with relationship of dobj\n",
    "    #Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "    rule2_pairs = []\n",
    "    for token in doc:\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        add_neg_pfx = False\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "                A = child.text\n",
    "                # check_spelling(child.text)\n",
    "\n",
    "            if((child.dep_ == \"dobj\" and child.pos_ == \"ADJ\") and not child.is_stop):\n",
    "                M = child.text\n",
    "                #check_spelling(child.text)\n",
    "\n",
    "            if(child.dep_ == \"neg\"):\n",
    "                neg_prefix = child.text\n",
    "                add_neg_pfx = True\n",
    "\n",
    "    if (add_neg_pfx and M != \"999999\"):\n",
    "        M = neg_prefix + \" \" + M\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            rule2_pairs.append((A, M,2))\n",
    "\n",
    "\n",
    "    ## THIRD RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "    ## Adjectival Complement - A is a child of something with relationship of nsubj, while\n",
    "    ## M is a child of the same something with relationship of acomp\n",
    "    ## Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "    ## \"The sound of the speakers would be better. The sound of the speakers could be better\" - handled using AUX dependency\n",
    "\n",
    "\n",
    "\n",
    "    rule3_pairs = []\n",
    "\n",
    "    for token in doc:\n",
    "\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        add_neg_pfx = False\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "                A = child.text\n",
    "                # check_spelling(child.text)\n",
    "\n",
    "            if(child.dep_ == \"acomp\" and not child.is_stop):\n",
    "                M = child.text\n",
    "\n",
    "            # example - 'this could have been better' -> (this, not better)\n",
    "            if(child.dep_ == \"aux\" and child.tag_ == \"MD\"):\n",
    "                neg_prefix = \"not\"\n",
    "                add_neg_pfx = True\n",
    "\n",
    "            if(child.dep_ == \"neg\"):\n",
    "                neg_prefix = child.text\n",
    "                add_neg_pfx = True\n",
    "\n",
    "        if (add_neg_pfx and M != \"999999\"):\n",
    "            M = neg_prefix + \" \" + M\n",
    "                #check_spelling(child.text)\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            rule3_pairs.append((A, M,3))\n",
    "\n",
    "    ## FOURTH RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "    #Adverbial modifier to a passive verb - A is a child of something with relationship of nsubjpass, while\n",
    "    # M is a child of the same something with relationship of advmod\n",
    "\n",
    "    #Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "    rule4_pairs = []\n",
    "    for token in doc:\n",
    "\n",
    "\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        add_neg_pfx = False\n",
    "        for child in children :\n",
    "            if((child.dep_ == \"nsubjpass\" or child.dep_ == \"nsubj\") and not child.is_stop):\n",
    "                A = child.text\n",
    "                # check_spelling(child.text)\n",
    "\n",
    "            if(child.dep_ == \"advmod\" and not child.is_stop):\n",
    "                M = child.text\n",
    "                M_children = child.children\n",
    "                for child_m in M_children:\n",
    "                    if(child_m.dep_ == \"advmod\"):\n",
    "                        M_hash = child_m.text\n",
    "                        M = M_hash + \" \" + child.text\n",
    "                        break\n",
    "                #check_spelling(child.text)\n",
    "\n",
    "            if(child.dep_ == \"neg\"):\n",
    "                neg_prefix = child.text\n",
    "                add_neg_pfx = True\n",
    "\n",
    "        if (add_neg_pfx and M != \"999999\"):\n",
    "            M = neg_prefix + \" \" + M\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            rule4_pairs.append((A, M,4)) # )\n",
    "\n",
    "\n",
    "    ## FIFTH RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "    #Complement of a copular verb - A is a child of M with relationship of nsubj, while\n",
    "    # M has a child with relationship of cop\n",
    "\n",
    "    #Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "    rule5_pairs = []\n",
    "    for token in doc:\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        buf_var = \"999999\"\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "                A = child.text\n",
    "                # check_spelling(child.text)\n",
    "\n",
    "            if(child.dep_ == \"cop\" and not child.is_stop):\n",
    "                buf_var = child.text\n",
    "                #check_spelling(child.text)\n",
    "\n",
    "        if(A != \"999999\" and buf_var != \"999999\"):\n",
    "            rule5_pairs.append((A, token.text,5))\n",
    "\n",
    "\n",
    "    ## SIXTH RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "    ## Example - \"It ok\", \"ok\" is INTJ (interjections like bravo, great etc)\n",
    "\n",
    "\n",
    "    rule6_pairs = []\n",
    "    for token in doc:\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        if(token.pos_ == \"INTJ\" and not token.is_stop):\n",
    "            for child in children :\n",
    "                if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "                    A = child.text\n",
    "                    M = token.text\n",
    "                    # check_spelling(child.text)\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            rule6_pairs.append((A, M,6))\n",
    "\n",
    "\n",
    "    ## SEVENTH RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "    ## ATTR - link between a verb like 'be/seem/appear' and its complement\n",
    "    ## Example: 'this is garbage' -> (this, garbage)\n",
    "\n",
    "    rule7_pairs = []\n",
    "    for token in doc:\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        add_neg_pfx = False\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "                A = child.text\n",
    "                # check_spelling(child.text)\n",
    "\n",
    "            if((child.dep_ == \"attr\") and not child.is_stop):\n",
    "                M = child.text\n",
    "                #check_spelling(child.text)\n",
    "\n",
    "            if(child.dep_ == \"neg\"):\n",
    "                neg_prefix = child.text\n",
    "                add_neg_pfx = True\n",
    "\n",
    "        if (add_neg_pfx and M != \"999999\"):\n",
    "            M = neg_prefix + \" \" + M\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            rule7_pairs.append((A, M,7))\n",
    "\n",
    "\n",
    "\n",
    "    aspects = []\n",
    "\n",
    "    aspects = rule1_pairs + rule2_pairs + rule3_pairs +rule4_pairs +rule5_pairs + rule6_pairs + rule7_pairs\n",
    "\n",
    "    # replace all instances of \"it\", \"this\" and \"they\" with \"product\"\n",
    "    tuple_list = [(A,M,r) if A not in prod_pronouns else (\"product\",M,r) for A,M,r in aspects ]\n",
    "    first_tuple_elements = [lemmatizer.lemmatize(a_tuple[0]) for a_tuple in tuple_list]\n",
    "    return first_tuple_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAspects(root, filename):\n",
    "    # JSON file \n",
    "    product_aspects = {}\n",
    "    f = open (root+filename, \"r\") \n",
    "    product_reviews = json.loads(f.read())\n",
    "    for id in product_reviews:\n",
    "        sentences = product_reviews[id]['edus']\n",
    "        for sentence in sentences:\n",
    "            aspects = aspect_extractor(sentence)\n",
    "            if product_reviews[id][\"entity_id\"] not in product_aspects:\n",
    "                product_aspects[product_reviews[id][\"entity_id\"]] = set()\n",
    "            product_aspects[product_reviews[id][\"entity_id\"]].update(aspects)\n",
    "    for prod in product_aspects:\n",
    "        product_aspects[prod] = list(product_aspects[prod])\n",
    "    out_file = open(\"product_aspects.json\", \"w\") \n",
    "  \n",
    "    json.dump(product_aspects, out_file, indent = 6) \n",
    "  \n",
    "    out_file.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
