{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitenvvenvde88aacb140049cab59668ffa038508f",
   "display_name": "Python 3.6.9 64-bit ('env': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../zero_shot/zero-shot-sent-cluster-vacc.json', 'r') as jfile:\n",
    "    sentence_json=json.load(jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0%|          | 0/10 [00:00<?, ?it/s](106, 768)\n(74, 768)\n(549, 768)\n(68, 768)\n(167, 768)\n(37, 768)\n(38, 768)\n 10%|█         | 1/10 [00:12<01:54, 12.77s/it](194, 768)\n(63, 768)\n(48, 768)\n(457, 768)\n(72, 768)\n(186, 768)\n(34, 768)\n(31, 768)\n 20%|██        | 2/10 [00:25<01:41, 12.73s/it](182, 768)\n(101, 768)\n(112, 768)\n(616, 768)\n(126, 768)\n(206, 768)\n(40, 768)\n(69, 768)\n 30%|███       | 3/10 [00:41<01:35, 13.66s/it](211, 768)\n(83, 768)\n(64, 768)\n(443, 768)\n(61, 768)\n(147, 768)\n(43, 768)\n(72, 768)\n 40%|████      | 4/10 [00:54<01:21, 13.64s/it](157, 768)\n(11, 768)\n(10, 768)\n(58, 768)\n(24, 768)\n(25, 768)\n(4, 768)\n(16, 768)\n 50%|█████     | 5/10 [00:58<00:53, 10.61s/it](44, 768)\n(141, 768)\n(122, 768)\n(1085, 768)\n(199, 768)\n(420, 768)\n(103, 768)\n(97, 768)\n 60%|██████    | 6/10 [01:29<01:07, 16.84s/it](374, 768)\n(164, 768)\n(194, 768)\n(460, 768)\n(163, 768)\n(193, 768)\n(80, 768)\n(85, 768)\n 70%|███████   | 7/10 [01:49<00:53, 17.70s/it](282, 768)\n(5, 768)\n(5, 768)\n(20, 768)\n(4, 768)\n(1, 768)\n 80%|████████  | 8/10 [01:50<00:25, 12.73s/it](3, 768)\n(8, 768)\n(61, 768)\n(187, 768)\n(321, 768)\n(82, 768)\n(99, 768)\n(27, 768)\n(25, 768)\n 90%|█████████ | 9/10 [02:02<00:12, 12.52s/it](79, 768)\n(17, 768)\n(34, 768)\n(125, 768)\n(39, 768)\n(56, 768)\n(16, 768)\n(15, 768)\n100%|██████████| 10/10 [02:08<00:00, 12.83s/it](60, 768)\n\n"
    }
   ],
   "source": [
    "#retrieving\n",
    "\n",
    "salient_clus={}\n",
    "\n",
    "for prod in tqdm(sentence_json):\n",
    "    #prod_cats={0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], -1:[]}\n",
    "\n",
    "    sentence_json[prod]\n",
    "    salient_clus[prod] = {}\n",
    "\n",
    "    for num_cluster in sentence_json[prod]:\n",
    "        clust_sents = sentence_json[prod][num_cluster]\n",
    "        clust_vecs = model.encode(clust_sents)\n",
    "        if clust_vecs.shape[0]==0:\n",
    "            continue\n",
    "        print(clust_vecs.shape)\n",
    "        centroid = np.mean(clust_vecs, axis=0)\n",
    "        similarities = cosine_similarity(clust_vecs, [centroid])\n",
    "        salient_sent = clust_sents[np.argmax(similarities)]\n",
    "        salient_clus[prod][num_cluster] = salient_sent\n",
    "\n",
    "\n",
    "\n",
    "#sent_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../zero_shot/cluster_vacc.json\",'w+') as jfile:\n",
    "            json.dump(salient_clus,jfile,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}