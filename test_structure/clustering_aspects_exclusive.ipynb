{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_aspect_cluster.json', 'r') as jfile:\n",
    "    aspect_json=json.load(jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_product_sentence_aspects.json', 'r') as jfile:\n",
    "    sentence_json=json.load(jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2041/2041 [05:56<00:00,  5.73it/s]\n"
     ]
    }
   ],
   "source": [
    "#generating cluster centers\n",
    "aspect_centres={}\n",
    "for prod in tqdm(aspect_json):\n",
    "    prod_cats={}\n",
    "    for i in range(8):\n",
    "        aspects=aspect_json[prod][str(i)]\n",
    "        if aspects==[]:\n",
    "            continue\n",
    "        vectors=model.encode(aspects)\n",
    "        centre=np.mean(vectors,0)\n",
    "        prod_cats[i]=centre\n",
    "    aspect_centres[prod]=prod_cats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2041/2041 [44:22<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "#assigning sentence to cluster\n",
    "\n",
    "sent_clust={}\n",
    "for prod in tqdm(sentence_json):\n",
    "    prod_cats={0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[]}\n",
    "    for sent in sentence_json[prod]:\n",
    "        cluster_centres=aspect_centres[prod]\n",
    "        sent_aspects=sent[1]\n",
    "        if sent_aspects==[]:\n",
    "            continue\n",
    "\n",
    "        sent_aspects_vec=model.encode(sent_aspects)\n",
    "        sent_aspects_centre=np.mean(sent_aspects_vec,0)\n",
    "        #print(np.array(list(cluster_centres.values())).shape)\n",
    "        #print(len(sent_aspects_centre))\n",
    "        similarities=cosine_similarity(np.array(list(cluster_centres.values())), [sent_aspects_centre]) \n",
    "        prod_cats[np.argmax(similarities)].append(sent[0])\n",
    "\n",
    "    sent_clust[prod]=prod_cats\n",
    "\n",
    "                \n",
    "                \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sent_clust_raw_exc.json', 'w') as jfile:\n",
    "    json.dump(sent_clust, jfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 2041/2041 [13:13<00:00,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "#retrieving\n",
    "\n",
    "salient_sents={}\n",
    "for prod in tqdm(sent_clust):\n",
    "    prod_cats={0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[]}\n",
    "    for clust in sent_clust[prod]:\n",
    "        clust_sents = sent_clust[prod][clust]\n",
    "        if clust_sents==[]:\n",
    "            continue\n",
    "        clust_vecs = model.encode(clust_sents)\n",
    "        centroid = np.mean(clust_vecs, axis=0)\n",
    "        #print(clust_vecs.shape)\n",
    "        #print(centroid)\n",
    "        similarities = cosine_similarity(clust_vecs, [centroid])\n",
    "        salient_sent = clust_sents[np.argmax(similarities)]\n",
    "        prod_cats[clust] = salient_sent\n",
    "    salient_sents[prod] = prod_cats\n",
    "        \n",
    "\n",
    "\n",
    "#sent_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: ' and is really light .\\nOne of my favorite things is ',\n",
       " 1: \" and gives extra room for the charger and a portable mouse .\\nIt 's constructed well \",\n",
       " 2: ' and also has a sturdy handle and shoulder strap .\\nLooks great too .',\n",
       " 3: \" left over in the computer compartment .\\nI 've been able to fit in about three extra notebooks in there , \",\n",
       " 4: \" I 've been able to stop carrying around paper and books \",\n",
       " 5: ' case is not durable .\\nThe inside fabric lining ',\n",
       " 6: 'If you have seen this at a retail store and then order from Amazon ',\n",
       " 7: ' so I wanted a smaller bag .\\nThis is the perfect size '}"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "#demo\n",
    "salient_sents['B002TR0LUG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('salient_sents_raw_exc.json','w+') as jfile:\n",
    "    json.dump(salient_sents,jfile,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}